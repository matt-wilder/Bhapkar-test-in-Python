{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c160f3ea-22f4-4d9f-97b5-edd7180a32f8",
   "metadata": {},
   "source": [
    "<h3> Bhapkar test in Python</h3>\n",
    "\n",
    "<p> Matt Wilder, University of Toronto <br>\n",
    "Please address questions and comments to <a href=\"mailto:matt.wilder@utoronto.ca\">matt.wilder@utoronto.ca</a>. </p>\n",
    "\n",
    "<p>Updated 25 March 2024</p>\n",
    "\n",
    "<p>This function runs Bhapkar's test from Bhapkar (1968) 'On the analysis of contingency tables with a quantitative response' <i> Biometrics, 24</i>(2): 329-38.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf1549-1918-4326-98ae-b1e6cd5c1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# reproduce the example from Bhakpar (1968) \n",
    "\n",
    "def bhapkar_test(n_ij, a_i, b_j):\n",
    "    N_j = n_ij.sum(axis=0)\n",
    "    A_i = np.array([np.sum(a_i * n_ij[:, j]) / N_j[j] for j in range(len(N_j))])\n",
    "    B_i = np.array([np.sum((a_i - A_i[j])**2 * (n_ij[:, j] / N_j[j])) for j in range(len(N_j))])\n",
    "    w_i = N_j / B_i\n",
    "    w = np.sum(w_i)\n",
    "    C = np.sum(w_i * A_i)\n",
    "    D = np.sum(b_j * w_i)\n",
    "    E = np.sum(b_j**2 * w_i)\n",
    "    F = np.sum(b_j * A_i * w_i)\n",
    "    \n",
    "    df_H1 = len(b_j) - 1\n",
    "    df_H2 = len(b_j) - 2\n",
    "    df_H3 = 1\n",
    "    \n",
    "    chi_squared_H1 = np.sum(w_i * A_i**2) - C**2 / w\n",
    "    \n",
    "    # calculate X hat and mu hat\n",
    "    denom = E * w - D**2\n",
    "    if denom > 0:\n",
    "        X_hat = (E * C - D * F) / denom\n",
    "        mu_hat = (w * F - C * D) / denom\n",
    "        chi_squared_H2 = np.sum(w_i * (A_i - (X_hat + b_j * mu_hat))**2)\n",
    "        chi_squared_H3 = chi_squared_H1 - chi_squared_H2\n",
    "    else:\n",
    "        X_hat = np.nan\n",
    "        mu_hat = np.nan\n",
    "        chi_squared_H2 = np.nan\n",
    "        chi_squared_H3 = np.nan\n",
    "    \n",
    "    # calculate p-values for each hypothesis test\n",
    "    p_value_H1 = chi2.sf(chi_squared_H1, df_H1) if not np.isnan(chi_squared_H1) else np.nan\n",
    "    p_value_H2 = chi2.sf(chi_squared_H2, df_H2) if not np.isnan(chi_squared_H2) else np.nan\n",
    "    p_value_H3 = chi2.sf(chi_squared_H3, df_H3) if not np.isnan(chi_squared_H3) else np.nan\n",
    "    \n",
    "    return {\n",
    "        'N_j': N_j, 'A_i': A_i, 'B_i': B_i, 'w_i': w_i, 'w': w, 'C': C, 'D': D, 'E': E, 'F': F,\n",
    "        'chi_squared_H0': chi_squared_H1, 'df_H0': df_H1, 'p_value_H0': p_value_H1,\n",
    "        'chi_squared_H1': chi_squared_H2, 'df_H1': df_H2, 'p_value_H1': p_value_H2,\n",
    "        'chi_squared_H2': chi_squared_H3, 'df_H2': df_H3, 'p_value_H2': p_value_H3,\n",
    "        'X_hat': X_hat, 'mu_hat': mu_hat\n",
    "    }\n",
    "\n",
    "# define the crosstab\n",
    "n_ij = np.array([\n",
    "    [141, 67, 114, 79, 39],  # teacher's ratings under different homework conditions from Bhakpar (1968)\n",
    "    [131, 66, 143, 72, 35],\n",
    "    [36, 14, 38, 28, 16]\n",
    "])\n",
    "a_i = np.array([1, 0, -1])  # scores for the teacher's rating categories from Bhakpar (1968)\n",
    "b_j = np.array([2, 1, 0, -1, -2])  # homework condition scores Bhakpar from (1968)\n",
    "\n",
    "# perform the test\n",
    "results = bhapkar_test(n_ij, a_i, b_j)\n",
    "\n",
    "# print the results\n",
    "print(f\"H₀ (Homogeneity of mean scores): χ² = {results['chi_squared_H0']:.2f}, df = {results['df_H0']}, p-value = {results['p_value_H0']:.4f}\")\n",
    "print(f\"H₁ (Linearity of regression): χ² = {results['chi_squared_H1']:.2f}, df = {results['df_H1']}, p-value = {results['p_value_H1']:.4f}\")\n",
    "print(f\"H₂ (Significance of regression coefficient): χ² = {results['chi_squared_H2']:.2f}, df = {results['df_H2']}, p-value = {results['p_value_H2']:.4f}\")\n",
    "\n",
    "# presentation of N_j, A_i, B_i, and w_i\n",
    "print(\"\\nSample sizes N for each condition j (Nj):\", results['N_j'])\n",
    "for index, (a, b, w) in enumerate(zip(results['A_i'], results['B_i'], results['w_i']), start=1):\n",
    "    print(f\"Group {index}: Mean Score (A{index}) = {a:.2f}, In-group Variability (B{index}) = {b:.2f}, Group Weight (w{index}) = {w:.2f}\")\n",
    "\n",
    "# explanation of variables\n",
    "print(\"\\nExplanation of variables:\")\n",
    "print(\"Nj: Sample sizes for each condition (j).\")\n",
    "print(\"Ai: Group mean scores, where 'i' denotes the group index.\")\n",
    "print(\"Bi: Measure of in-group variability for each group 'i'.\")\n",
    "print(\"w: Weight assigned to each group 'i', calculated based on Bi and sample size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ebbf0-2982-41bb-837c-aace258222f0",
   "metadata": {},
   "source": [
    "<b><br>Original results from Bhapkar (1968):</b>\n",
    "\n",
    "<i>H</i><sub>0</sub> (Homogeneity of mean scores): χ2 = 3.957, df = 4, <i>p</i>-value not provided but stated as insignificant.\n",
    "<i>H</i><sub>1</sub> (Linearity of regression): χ<sup>2</sup> = 1.578, df = 3, <i>p</i>-value not provided but stated as insignificant.\n",
    "<i>H</i><sub>2</sub> (Significance of the regression coefficient): χ2 = 2.379, df = 1, <i>p</i>-value not provided but stated as insignificant.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
